# 🎯 CodSoft Internship - Task 3: Image Caption Generator 🖼️🧠

This project is part of the **CodSoft AI Internship (June–July 2025)**.  
The task was to create an AI-powered tool that generates accurate and natural language captions from uploaded images using Computer Vision and Natural Language Processing.

---

## 📌 Project Overview

This notebook uses a **pretrained Vision Transformer (ViT)** as the image encoder and **GPT2** as the decoder to generate captions.

🔧 **Technologies Used**:
- Python
- Hugging Face Transformers
- ViT + GPT2
- Gradio (for UI)
- Google Colab

---

## 🚀 How It Works

1. Upload an image through the Gradio UI
2. AI extracts features from the image using **ViT**
3. **GPT2** generates a relevant caption based on the features
4. The caption is displayed instantly

---

## 🖼️ Example Output

> **Image**: Dog sitting on a couch  
> **Generated Caption**: *"A dog sitting on a sofa in a living room."*

---

## 📂 Files Included

| File Name | Description |
|-----------|-------------|
| `codsoft_task3_image_captioning.ipynb` | The complete Colab notebook with model and UI |
| `README.md` | This file |
| *(optional)* Screenshots/ | Image outputs ![Screenshot 2025-07-04 194613](https://github.com/user-attachments/assets/80358ac6-7b8e-4abf-b217-192c7636ab70)
![Screenshot 2025-07-04 194412](https://github.com/user-attachments/assets/fb2de9de-9497-49e3-b6d0-803daa8cc620)
![Screenshot 2025-07-04 194217](https://github.com/user-attachments/assets/bba0849d-2e03-405e-899c-59e9cbeed765)
|

---

## 💡 What I Learned

- How computer vision models like ViT work
- How transformers generate text from image features
- Creating web interfaces using Gradio
- Real-world application of combining CV + NLP

---

## 🙋‍♂️ Author

**Rushikesh Baban Kedar**  
CodSoft AI Internship – Batch June 2025  
🔗 [My LinkedIn Profile](https://www.linkedin.com/in/rushikesh-kedar-87106b373)

---

## ✅ Task Description (from CodSoft)

> "Build an AI-based image captioning model using pre-trained vision models like VGG or ResNet along with a language model like RNN or Transformer to generate image captions."

✔️ This project uses:
- ✅ Vision Transformer (ViT) in place of VGG/ResNet  
- ✅ Transformer-based GPT2 instead of RNN  
- ✅ Hugging Face’s `VisionEncoderDecoderModel`

---

## 🎯 Status

✅ Task Completed  
📤 Shared on LinkedIn & GitHub  
📩 Submitted to CodSoft

---

## 🙏 Special Thanks

Big thanks to **@CodSoft** for the opportunity to work on this meaningful internship project and apply AI practically.

